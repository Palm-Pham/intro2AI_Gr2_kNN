{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the data\n",
    "def initData(filename, training_ratio, validation_ratio, test_ratio, attributes):\n",
    "    with open(filename, 'r', newline='') as file:\n",
    "        file_csv = csv.reader(file)\n",
    "        full_header = next(file_csv)  # Read the full header row\n",
    "\n",
    "        # Identify indices for the chosen attributes\n",
    "        chosen_indices = [full_header.index(attr) for attr in attributes]\n",
    "        labels = []\n",
    "        data = []\n",
    "\n",
    "        for row in file_csv:\n",
    "            if len(row) < len(full_header):\n",
    "                continue\n",
    "            \n",
    "            # Extract chosen attributes and convert to float\n",
    "            features = [float(row[i]) for i in chosen_indices]\n",
    "            \n",
    "            # Assume the last column is the label\n",
    "            label = row[-1]\n",
    "            data.append(features + [label])\n",
    "            \n",
    "            if label not in labels:\n",
    "                labels.append(label)\n",
    "\n",
    "        len_data = len(data)\n",
    "        print(f\"Total rows read: {len_data}\")\n",
    "\n",
    "        # Split into training, validation, and test sets\n",
    "        train_idx = int(training_ratio * len_data)\n",
    "        val_idx = int((training_ratio + validation_ratio) * len_data)\n",
    "        \n",
    "        training_data = data[:train_idx]\n",
    "        validation_data = data[train_idx:val_idx]\n",
    "        test_data = data[val_idx:]\n",
    "\n",
    "        if len(training_data) == 0 or len(validation_data) == 0:\n",
    "            print(\"[ERROR] Training or validation set is empty. Check your data split.\")\n",
    "            exit()\n",
    "    \n",
    "    chosen_header = [full_header[i] for i in chosen_indices]\n",
    "    return chosen_header, training_data, validation_data, test_data, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minkowski_distance(point_1, point_2, p):\n",
    "    return sum(abs(a - b)**p for a, b in zip(point_1, point_2))**(1/p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(training_data, new_point, k, p):\n",
    "    distances = [\n",
    "        (minkowski_distance(new_point, row[:-1], p), row[-1])\n",
    "        for row in training_data\n",
    "    ]\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Perform voting among the k nearest neighbors\n",
    "    votes = {}\n",
    "    for i in range(k):\n",
    "        label = distances[i][1]\n",
    "        votes[label] = votes.get(label, 0) + 1\n",
    "    \n",
    "    return max(votes, key=votes.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(training_data, data, k, p):\n",
    "\n",
    "    if not data:\n",
    "        return 0\n",
    "    correct = sum(\n",
    "        knn(training_data, point[:-1], k, p) == point[-1]\n",
    "        for point in data\n",
    "    )\n",
    "    return correct / len(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_map(training_data, attributes, k, p, grid_step):\n",
    "    print(\"[DEBUG] Generating decision map... This can take time if the range is large.\")\n",
    "    \n",
    "    # Extract x, y, and labels from the training data\n",
    "    x_vals = [row[0] for row in training_data]\n",
    "    y_vals = [row[1] for row in training_data]\n",
    "    data_labels = [row[-1] for row in training_data]\n",
    "    \n",
    "    # Define the plot range\n",
    "    x_min, x_max = min(x_vals) - 1, max(x_vals) + 1\n",
    "    y_min, y_max = min(y_vals) - 1, max(y_vals) + 1\n",
    "    \n",
    "    # Generate a grid of points for the decision map\n",
    "    xx, yy = np.meshgrid(\n",
    "        np.arange(x_min, x_max, grid_step),\n",
    "        np.arange(y_min, y_max, grid_step)\n",
    "    )\n",
    "    \n",
    "    # Classify each grid point\n",
    "    Z = np.array([\n",
    "        knn(training_data, [mx, my], k, p)\n",
    "        for mx, my in zip(xx.ravel(), yy.ravel())\n",
    "    ]).reshape(xx.shape)\n",
    "    \n",
    "    # Map labels to integers for coloring\n",
    "    unique_labels = sorted(set(data_labels))\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(unique_labels)))\n",
    "    color_map = ListedColormap(colors)\n",
    "    label_to_idx = {lab: idx for idx, lab in enumerate(unique_labels)}\n",
    "    Z_int = np.vectorize(label_to_idx.get)(Z)\n",
    "    \n",
    "    # Plot decision regions\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    contour = ax.pcolormesh(\n",
    "        xx, yy, Z_int,\n",
    "        cmap=color_map, alpha=0.2, shading='auto'\n",
    "    )\n",
    "    \n",
    "    # Plot training points\n",
    "    for label in unique_labels:\n",
    "        mask = [row[-1] == label for row in training_data]\n",
    "        x = [row[0] for row, m in zip(training_data, mask) if m][:100]\n",
    "        y = [row[1] for row, m in zip(training_data, mask) if m][:100]\n",
    "        ax.scatter(\n",
    "            x, y,\n",
    "            c=[color_map(label_to_idx[label])],\n",
    "            label=label,\n",
    "            edgecolor='black', linewidth=0.1,\n",
    "            s=10\n",
    "        )\n",
    "    \n",
    "    # Labels, title, and legend\n",
    "    ax.set_xlabel(attributes[0], fontsize=12)\n",
    "    ax.set_ylabel(attributes[1], fontsize=12)\n",
    "    ax.set_title(f\"Decision Boundaries: {attributes[0]} vs {attributes[1]}\\nk={k}, p={p}\", fontsize=14, pad=15)\n",
    "    ax.legend(title=\"Classes\", bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "    ax.grid(True, linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Save and display the figure\n",
    "    plt.tight_layout()\n",
    "    out_filename = f\"decision_map_{attributes[0]}_{attributes[1]}_k{k}_p{p}.png\"\n",
    "    plt.savefig(out_filename, dpi=300, bbox_inches='tight')\n",
    "    print(f\"[DEBUG] Decision map saved as '{out_filename}'\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows read: 5000\n"
     ]
    }
   ],
   "source": [
    "dataset_file = 'updated_pollution_dataset.csv'\n",
    "attributes = ['Temperature', 'SO2']  # Two selected attributes\n",
    "k = 6\n",
    "p = 4\n",
    "grid_step = 0.1  # Grid step size for faster computation\n",
    "\n",
    "# Split ratios\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.2\n",
    "test_ratio = 0.5\n",
    "\n",
    "# Load data\n",
    "chosen_header, training_data, validation_data, test_data, labels = initData(\n",
    "    filename=dataset_file,\n",
    "    training_ratio=training_ratio,\n",
    "    validation_ratio=validation_ratio,\n",
    "    test_ratio=test_ratio,\n",
    "    attributes=attributes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample point: [22.6, 7.5, 'Good']\n",
      "First 6 neighbors: [(0.2378414230005439, 'Good'), (0.29999999999999716, 'Good'), (0.2999999999999998, 'Good'), (0.3009216698434571, 'Good'), (0.31382889927150026, 'Good'), (0.40000000000000036, 'Good')]\n",
      "Predicted label: Good\n",
      "Votes: {'Good': 6}\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Choose a sample point to demonstrate the classification process\n",
    "# input: a random point in the validation set, the corresponding attribute values\n",
    "# output: first k neighbors and the predicted label\n",
    "#         the vote of each label among the k neighbors\n",
    "#         Hence the predicted label\n",
    "\n",
    "# Select a random point from the validation set\n",
    "sample_point = random.choice(test_data)\n",
    "# sample_point = test_data[0]\n",
    "print(f\"Sample point: {sample_point}\")\n",
    "\n",
    "# Calculate distances to all points in the training set\n",
    "neighbors = [\n",
    "    (minkowski_distance(sample_point[:-1], row[:-1], p), row[-1])\n",
    "    for row in training_data\n",
    "]\n",
    "\n",
    "# Sort and select the first k neighbors\n",
    "neighbors.sort(key=lambda x: x[0])\n",
    "first_k_neighbors = neighbors[:k]\n",
    "print(f\"First {k} neighbors: {first_k_neighbors}\")\n",
    "\n",
    "# Predict the label based on the neighbors\n",
    "predicted_label = knn(training_data, sample_point[:-1], k, p)\n",
    "print(f\"Predicted label: {predicted_label}\")\n",
    "\n",
    "# Calculate the vote of each label among the k neighbors\n",
    "votes = {}\n",
    "for distance, label in first_k_neighbors:\n",
    "    votes[label] = votes.get(label, 0) + 1\n",
    "\n",
    "print(f\"Votes: {votes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute accuracy\n",
    "acc_val = compute_accuracy(training_data, validation_data, k, p)\n",
    "acc_test = compute_accuracy(training_data, test_data, k, p)\n",
    "print(f\"Validation accuracy: {acc_val:.3f}\")\n",
    "print(f\"Test accuracy: {acc_test:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot decision map\n",
    "plot_decision_map(training_data, attributes, k, p, grid_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ds_envi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
