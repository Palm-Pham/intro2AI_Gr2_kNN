{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows read: 5000\n"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "# Initialize the data\n",
    "def initData(filename, training_ratio, validation_ratio, test_ratio, attributes):\n",
    "    with open(filename, 'r', newline='') as file:\n",
    "        file_csv = csv.reader(file)\n",
    "        full_header = next(file_csv)  # Read the full header row\n",
    "\n",
    "        # Identify indices for the chosen attributes\n",
    "        chosen_indices = [full_header.index(attr) for attr in attributes]\n",
    "        labels = []\n",
    "        data = []\n",
    "\n",
    "        for row in file_csv:\n",
    "            if len(row) < len(full_header):\n",
    "                continue\n",
    "            \n",
    "            # Extract chosen attributes and convert to float\n",
    "            features = [float(row[i]) for i in chosen_indices]\n",
    "            \n",
    "            # Assume the last column is the label\n",
    "            label = row[-1]\n",
    "            data.append(features + [label])\n",
    "            \n",
    "            if label not in labels:\n",
    "                labels.append(label)\n",
    "\n",
    "        len_data = len(data)\n",
    "        print(f\"Total rows read: {len_data}\")\n",
    "\n",
    "        # Split into training, validation, and test sets\n",
    "        train_idx = int(training_ratio * len_data)\n",
    "        val_idx = int((training_ratio + validation_ratio) * len_data)\n",
    "        \n",
    "        training_data = data[:train_idx]\n",
    "        validation_data = data[train_idx:val_idx]\n",
    "        test_data = data[val_idx:]\n",
    "\n",
    "        if len(training_data) == 0 or len(validation_data) == 0:\n",
    "            print(\"[ERROR] Training or validation set is empty. Check your data split.\")\n",
    "            exit()\n",
    "    \n",
    "    chosen_header = [full_header[i] for i in chosen_indices]\n",
    "    return chosen_header, training_data, validation_data, test_data, labels\n",
    "\n",
    "\n",
    "# %%\n",
    "def minkowski_distance(point_1, point_2, p):\n",
    "    return sum(abs(a - b)**p for a, b in zip(point_1, point_2))**(1/p)\n",
    "\n",
    "\n",
    "# %%\n",
    "def knn(training_data, new_point, k, p):\n",
    "    distances = [\n",
    "        (minkowski_distance(new_point, row[:-1], p), row[-1])\n",
    "        for row in training_data\n",
    "    ]\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    \n",
    "    # Perform voting among the k nearest neighbors\n",
    "    votes = {}\n",
    "    for i in range(k):\n",
    "        label = distances[i][1]\n",
    "        votes[label] = votes.get(label, 0) + 1\n",
    "    \n",
    "    return max(votes, key=votes.get)\n",
    "\n",
    "# %%\n",
    "def compute_accuracy(training_data, data, k, p):\n",
    "\n",
    "    if not data:\n",
    "        return 0\n",
    "    correct = sum(\n",
    "        knn(training_data, point[:-1], k, p) == point[-1]\n",
    "        for point in data\n",
    "    )\n",
    "    return correct / len(data)\n",
    "\n",
    "# %%\n",
    "dataset_file = 'final_pollution_dataset.csv'\n",
    "attributes = ['SO2', 'CO', 'Proximity_to_Industrial_Areas']  # Two selected attributes\n",
    "\n",
    "# Split ratios\n",
    "training_ratio = 0.7\n",
    "validation_ratio = 0.1\n",
    "test_ratio = 0.2\n",
    "\n",
    "# Load data\n",
    "chosen_header, training_data, validation_data, test_data, labels = initData(\n",
    "    filename=dataset_file,\n",
    "    training_ratio=training_ratio,\n",
    "    validation_ratio=validation_ratio,\n",
    "    test_ratio=test_ratio,\n",
    "    attributes=attributes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def scale_data(training_data, validation_data, test_data):\n",
    "    \"\"\"\n",
    "    Scale features using StandardScaler while preserving labels\n",
    "    \"\"\"\n",
    "    # Extract features and labels\n",
    "    train_features = np.array([row[:-1] for row in training_data])\n",
    "    val_features = np.array([row[:-1] for row in validation_data])\n",
    "    test_features = np.array([row[:-1] for row in test_data])\n",
    "    \n",
    "    # Get labels\n",
    "    train_labels = [row[-1] for row in training_data]\n",
    "    val_labels = [row[-1] for row in validation_data]\n",
    "    test_labels = [row[-1] for row in test_data]\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    train_scaled = scaler.fit_transform(train_features)\n",
    "    val_scaled = scaler.transform(val_features)\n",
    "    test_scaled = scaler.transform(test_features)\n",
    "    \n",
    "    # Combine scaled features with labels\n",
    "    training_scaled = [list(features) + [label] for features, label in zip(train_scaled, train_labels)]\n",
    "    validation_scaled = [list(features) + [label] for features, label in zip(val_scaled, val_labels)]\n",
    "    test_scaled = [list(features) + [label] for features, label in zip(test_scaled, test_labels)]\n",
    "    \n",
    "    return training_scaled, validation_scaled, test_scaled\n",
    "\n",
    "# Add this after data loading in main():\n",
    "training_data, validation_data, test_data = scale_data(training_data, validation_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1, p=1: val_acc=0.854, test_acc=0.864\n",
      "k=1, p=2: val_acc=0.852, test_acc=0.870\n",
      "k=1, p=3: val_acc=0.852, test_acc=0.869\n",
      "k=1, p=4: val_acc=0.858, test_acc=0.868\n",
      "k=1, p=5: val_acc=0.856, test_acc=0.867\n",
      "k=1, p=6: val_acc=0.856, test_acc=0.868\n",
      "k=1, p=7: val_acc=0.858, test_acc=0.867\n",
      "k=1, p=8: val_acc=0.860, test_acc=0.868\n",
      "k=1, p=9: val_acc=0.858, test_acc=0.869\n",
      "k=2, p=1: val_acc=0.854, test_acc=0.864\n",
      "k=2, p=2: val_acc=0.852, test_acc=0.870\n",
      "k=2, p=3: val_acc=0.852, test_acc=0.869\n",
      "k=2, p=4: val_acc=0.858, test_acc=0.868\n",
      "k=2, p=5: val_acc=0.856, test_acc=0.867\n",
      "k=2, p=6: val_acc=0.856, test_acc=0.868\n",
      "k=2, p=7: val_acc=0.858, test_acc=0.867\n",
      "k=2, p=8: val_acc=0.860, test_acc=0.868\n",
      "k=2, p=9: val_acc=0.858, test_acc=0.869\n",
      "k=3, p=1: val_acc=0.896, test_acc=0.885\n",
      "k=3, p=2: val_acc=0.882, test_acc=0.880\n",
      "k=3, p=3: val_acc=0.888, test_acc=0.876\n",
      "k=3, p=4: val_acc=0.888, test_acc=0.874\n",
      "k=3, p=5: val_acc=0.884, test_acc=0.878\n",
      "k=3, p=6: val_acc=0.884, test_acc=0.878\n",
      "k=3, p=7: val_acc=0.884, test_acc=0.879\n",
      "k=3, p=8: val_acc=0.888, test_acc=0.880\n",
      "k=3, p=9: val_acc=0.890, test_acc=0.881\n",
      "k=4, p=1: val_acc=0.898, test_acc=0.888\n",
      "k=4, p=2: val_acc=0.892, test_acc=0.885\n",
      "k=4, p=3: val_acc=0.892, test_acc=0.882\n",
      "k=4, p=4: val_acc=0.892, test_acc=0.881\n",
      "k=4, p=5: val_acc=0.890, test_acc=0.883\n",
      "k=4, p=6: val_acc=0.892, test_acc=0.884\n",
      "k=4, p=7: val_acc=0.894, test_acc=0.885\n",
      "k=4, p=8: val_acc=0.896, test_acc=0.886\n",
      "k=4, p=9: val_acc=0.892, test_acc=0.886\n",
      "k=5, p=1: val_acc=0.914, test_acc=0.887\n",
      "k=5, p=2: val_acc=0.920, test_acc=0.886\n",
      "k=5, p=3: val_acc=0.912, test_acc=0.886\n",
      "k=5, p=4: val_acc=0.910, test_acc=0.889\n",
      "k=5, p=5: val_acc=0.904, test_acc=0.888\n",
      "k=5, p=6: val_acc=0.902, test_acc=0.890\n",
      "k=5, p=7: val_acc=0.900, test_acc=0.892\n",
      "k=5, p=8: val_acc=0.902, test_acc=0.893\n",
      "k=5, p=9: val_acc=0.902, test_acc=0.894\n",
      "k=6, p=1: val_acc=0.912, test_acc=0.891\n",
      "k=6, p=2: val_acc=0.910, test_acc=0.890\n",
      "k=6, p=3: val_acc=0.910, test_acc=0.891\n",
      "k=6, p=4: val_acc=0.910, test_acc=0.889\n",
      "k=6, p=5: val_acc=0.906, test_acc=0.889\n",
      "k=6, p=6: val_acc=0.904, test_acc=0.890\n",
      "k=6, p=7: val_acc=0.906, test_acc=0.890\n",
      "k=6, p=8: val_acc=0.906, test_acc=0.890\n",
      "k=6, p=9: val_acc=0.906, test_acc=0.890\n",
      "k=7, p=1: val_acc=0.914, test_acc=0.893\n",
      "k=7, p=2: val_acc=0.914, test_acc=0.892\n",
      "k=7, p=3: val_acc=0.910, test_acc=0.894\n",
      "k=7, p=4: val_acc=0.908, test_acc=0.895\n",
      "k=7, p=5: val_acc=0.908, test_acc=0.894\n",
      "k=7, p=6: val_acc=0.906, test_acc=0.893\n",
      "k=7, p=7: val_acc=0.906, test_acc=0.892\n",
      "k=7, p=8: val_acc=0.910, test_acc=0.890\n",
      "k=7, p=9: val_acc=0.910, test_acc=0.890\n",
      "k=8, p=1: val_acc=0.908, test_acc=0.893\n",
      "k=8, p=2: val_acc=0.910, test_acc=0.897\n",
      "k=8, p=3: val_acc=0.916, test_acc=0.899\n",
      "k=8, p=4: val_acc=0.912, test_acc=0.893\n",
      "k=8, p=5: val_acc=0.912, test_acc=0.888\n",
      "k=8, p=6: val_acc=0.910, test_acc=0.888\n",
      "k=8, p=7: val_acc=0.912, test_acc=0.886\n",
      "k=8, p=8: val_acc=0.910, test_acc=0.888\n",
      "k=8, p=9: val_acc=0.910, test_acc=0.887\n",
      "k=9, p=1: val_acc=0.906, test_acc=0.886\n",
      "k=9, p=2: val_acc=0.904, test_acc=0.894\n",
      "k=9, p=3: val_acc=0.908, test_acc=0.895\n",
      "k=9, p=4: val_acc=0.906, test_acc=0.891\n",
      "k=9, p=5: val_acc=0.902, test_acc=0.890\n",
      "k=9, p=6: val_acc=0.904, test_acc=0.890\n",
      "k=9, p=7: val_acc=0.904, test_acc=0.891\n",
      "k=9, p=8: val_acc=0.904, test_acc=0.891\n",
      "k=9, p=9: val_acc=0.904, test_acc=0.891\n",
      "k=10, p=1: val_acc=0.906, test_acc=0.892\n",
      "k=10, p=2: val_acc=0.902, test_acc=0.894\n",
      "k=10, p=3: val_acc=0.904, test_acc=0.893\n",
      "k=10, p=4: val_acc=0.910, test_acc=0.893\n",
      "k=10, p=5: val_acc=0.908, test_acc=0.894\n",
      "k=10, p=6: val_acc=0.908, test_acc=0.893\n",
      "k=10, p=7: val_acc=0.910, test_acc=0.891\n",
      "k=10, p=8: val_acc=0.908, test_acc=0.891\n",
      "k=10, p=9: val_acc=0.908, test_acc=0.892\n",
      "k=11, p=1: val_acc=0.906, test_acc=0.888\n",
      "k=11, p=2: val_acc=0.904, test_acc=0.890\n",
      "k=11, p=3: val_acc=0.908, test_acc=0.891\n",
      "k=11, p=4: val_acc=0.910, test_acc=0.892\n",
      "k=11, p=5: val_acc=0.906, test_acc=0.890\n",
      "k=11, p=6: val_acc=0.904, test_acc=0.889\n",
      "k=11, p=7: val_acc=0.904, test_acc=0.889\n",
      "k=11, p=8: val_acc=0.906, test_acc=0.888\n",
      "k=11, p=9: val_acc=0.908, test_acc=0.888\n",
      "k=12, p=1: val_acc=0.908, test_acc=0.889\n",
      "k=12, p=2: val_acc=0.910, test_acc=0.891\n",
      "k=12, p=3: val_acc=0.906, test_acc=0.891\n",
      "k=12, p=4: val_acc=0.912, test_acc=0.893\n",
      "k=12, p=5: val_acc=0.912, test_acc=0.892\n",
      "k=12, p=6: val_acc=0.908, test_acc=0.892\n",
      "k=12, p=7: val_acc=0.908, test_acc=0.891\n",
      "k=12, p=8: val_acc=0.908, test_acc=0.891\n",
      "k=12, p=9: val_acc=0.908, test_acc=0.891\n",
      "k=13, p=1: val_acc=0.904, test_acc=0.885\n",
      "k=13, p=2: val_acc=0.912, test_acc=0.891\n",
      "k=13, p=3: val_acc=0.910, test_acc=0.892\n",
      "k=13, p=4: val_acc=0.912, test_acc=0.893\n",
      "k=13, p=5: val_acc=0.910, test_acc=0.892\n",
      "k=13, p=6: val_acc=0.912, test_acc=0.892\n",
      "k=13, p=7: val_acc=0.910, test_acc=0.891\n",
      "k=13, p=8: val_acc=0.910, test_acc=0.891\n",
      "k=13, p=9: val_acc=0.912, test_acc=0.892\n",
      "k=14, p=1: val_acc=0.910, test_acc=0.889\n",
      "k=14, p=2: val_acc=0.910, test_acc=0.896\n",
      "k=14, p=3: val_acc=0.910, test_acc=0.891\n",
      "k=14, p=4: val_acc=0.910, test_acc=0.890\n",
      "k=14, p=5: val_acc=0.908, test_acc=0.892\n",
      "k=14, p=6: val_acc=0.908, test_acc=0.894\n",
      "k=14, p=7: val_acc=0.908, test_acc=0.894\n",
      "k=14, p=8: val_acc=0.908, test_acc=0.894\n",
      "k=14, p=9: val_acc=0.906, test_acc=0.893\n",
      "k=15, p=1: val_acc=0.908, test_acc=0.892\n",
      "k=15, p=2: val_acc=0.910, test_acc=0.898\n",
      "k=15, p=3: val_acc=0.908, test_acc=0.897\n",
      "k=15, p=4: val_acc=0.908, test_acc=0.897\n",
      "k=15, p=5: val_acc=0.902, test_acc=0.894\n",
      "k=15, p=6: val_acc=0.904, test_acc=0.895\n",
      "k=15, p=7: val_acc=0.904, test_acc=0.894\n",
      "k=15, p=8: val_acc=0.904, test_acc=0.893\n",
      "k=15, p=9: val_acc=0.902, test_acc=0.892\n",
      "k=16, p=1: val_acc=0.906, test_acc=0.891\n",
      "k=16, p=2: val_acc=0.914, test_acc=0.895\n",
      "k=16, p=3: val_acc=0.910, test_acc=0.895\n",
      "k=16, p=4: val_acc=0.908, test_acc=0.895\n",
      "k=16, p=5: val_acc=0.908, test_acc=0.892\n",
      "k=16, p=6: val_acc=0.904, test_acc=0.892\n",
      "k=16, p=7: val_acc=0.904, test_acc=0.892\n",
      "k=16, p=8: val_acc=0.904, test_acc=0.892\n",
      "k=16, p=9: val_acc=0.904, test_acc=0.892\n",
      "k=17, p=1: val_acc=0.908, test_acc=0.890\n",
      "k=17, p=2: val_acc=0.910, test_acc=0.898\n",
      "k=17, p=3: val_acc=0.912, test_acc=0.897\n",
      "k=17, p=4: val_acc=0.906, test_acc=0.894\n",
      "k=17, p=5: val_acc=0.906, test_acc=0.894\n",
      "k=17, p=6: val_acc=0.904, test_acc=0.893\n",
      "k=17, p=7: val_acc=0.902, test_acc=0.893\n",
      "k=17, p=8: val_acc=0.902, test_acc=0.894\n",
      "k=17, p=9: val_acc=0.904, test_acc=0.894\n",
      "k=18, p=1: val_acc=0.908, test_acc=0.889\n",
      "k=18, p=2: val_acc=0.908, test_acc=0.897\n",
      "k=18, p=3: val_acc=0.908, test_acc=0.895\n",
      "k=18, p=4: val_acc=0.908, test_acc=0.891\n",
      "k=18, p=5: val_acc=0.906, test_acc=0.891\n",
      "k=18, p=6: val_acc=0.906, test_acc=0.893\n",
      "k=18, p=7: val_acc=0.906, test_acc=0.892\n",
      "k=18, p=8: val_acc=0.906, test_acc=0.893\n",
      "k=18, p=9: val_acc=0.906, test_acc=0.893\n",
      "k=19, p=1: val_acc=0.908, test_acc=0.890\n",
      "k=19, p=2: val_acc=0.908, test_acc=0.900\n",
      "k=19, p=3: val_acc=0.906, test_acc=0.897\n",
      "k=19, p=4: val_acc=0.900, test_acc=0.894\n",
      "k=19, p=5: val_acc=0.902, test_acc=0.894\n",
      "k=19, p=6: val_acc=0.902, test_acc=0.895\n",
      "k=19, p=7: val_acc=0.904, test_acc=0.893\n",
      "k=19, p=8: val_acc=0.904, test_acc=0.894\n",
      "k=19, p=9: val_acc=0.904, test_acc=0.893\n",
      "Validation Accuracies:\n",
      "[[0.85370741 0.85170341 0.85170341 0.85771543 0.85571142 0.85571142\n",
      "  0.85771543 0.85971944 0.85771543]\n",
      " [0.85370741 0.85170341 0.85170341 0.85771543 0.85571142 0.85571142\n",
      "  0.85771543 0.85971944 0.85771543]\n",
      " [0.89579158 0.88176353 0.88777555 0.88777555 0.88376754 0.88376754\n",
      "  0.88376754 0.88777555 0.88977956]\n",
      " [0.89779559 0.89178357 0.89178357 0.89178357 0.88977956 0.89178357\n",
      "  0.89378758 0.89579158 0.89178357]\n",
      " [0.91382766 0.91983968 0.91182365 0.90981964 0.90380762 0.90180361\n",
      "  0.8997996  0.90180361 0.90180361]\n",
      " [0.91182365 0.90981964 0.90981964 0.90981964 0.90581162 0.90380762\n",
      "  0.90581162 0.90581162 0.90581162]\n",
      " [0.91382766 0.91382766 0.90981964 0.90781563 0.90781563 0.90581162\n",
      "  0.90581162 0.90981964 0.90981964]\n",
      " [0.90781563 0.90981964 0.91583166 0.91182365 0.91182365 0.90981964\n",
      "  0.91182365 0.90981964 0.90981964]\n",
      " [0.90581162 0.90380762 0.90781563 0.90581162 0.90180361 0.90380762\n",
      "  0.90380762 0.90380762 0.90380762]\n",
      " [0.90581162 0.90180361 0.90380762 0.90981964 0.90781563 0.90781563\n",
      "  0.90981964 0.90781563 0.90781563]\n",
      " [0.90581162 0.90380762 0.90781563 0.90981964 0.90581162 0.90380762\n",
      "  0.90380762 0.90581162 0.90781563]\n",
      " [0.90781563 0.90981964 0.90581162 0.91182365 0.91182365 0.90781563\n",
      "  0.90781563 0.90781563 0.90781563]\n",
      " [0.90380762 0.91182365 0.90981964 0.91182365 0.90981964 0.91182365\n",
      "  0.90981964 0.90981964 0.91182365]\n",
      " [0.90981964 0.90981964 0.90981964 0.90981964 0.90781563 0.90781563\n",
      "  0.90781563 0.90781563 0.90581162]\n",
      " [0.90781563 0.90981964 0.90781563 0.90781563 0.90180361 0.90380762\n",
      "  0.90380762 0.90380762 0.90180361]\n",
      " [0.90581162 0.91382766 0.90981964 0.90781563 0.90781563 0.90380762\n",
      "  0.90380762 0.90380762 0.90380762]\n",
      " [0.90781563 0.90981964 0.91182365 0.90581162 0.90581162 0.90380762\n",
      "  0.90180361 0.90180361 0.90380762]\n",
      " [0.90781563 0.90781563 0.90781563 0.90781563 0.90581162 0.90581162\n",
      "  0.90581162 0.90581162 0.90581162]\n",
      " [0.90781563 0.90781563 0.90581162 0.8997996  0.90180361 0.90180361\n",
      "  0.90380762 0.90380762 0.90380762]]\n",
      "Test Accuracies:\n",
      "[[0.86413586 0.87012987 0.86913087 0.86813187 0.86713287 0.86813187\n",
      "  0.86713287 0.86813187 0.86913087]\n",
      " [0.86413586 0.87012987 0.86913087 0.86813187 0.86713287 0.86813187\n",
      "  0.86713287 0.86813187 0.86913087]\n",
      " [0.88511489 0.88011988 0.87612388 0.87412587 0.87812188 0.87812188\n",
      "  0.87912088 0.88011988 0.88111888]\n",
      " [0.88811189 0.88511489 0.88211788 0.88111888 0.88311688 0.88411588\n",
      "  0.88511489 0.88611389 0.88611389]\n",
      " [0.88711289 0.88611389 0.88611389 0.88911089 0.88811189 0.89010989\n",
      "  0.89210789 0.89310689 0.89410589]\n",
      " [0.89110889 0.89010989 0.89110889 0.88911089 0.88911089 0.89010989\n",
      "  0.89010989 0.89010989 0.89010989]\n",
      " [0.89310689 0.89210789 0.89410589 0.8951049  0.89410589 0.89310689\n",
      "  0.89210789 0.89010989 0.89010989]\n",
      " [0.89310689 0.8971029  0.8991009  0.89310689 0.88811189 0.88811189\n",
      "  0.88611389 0.88811189 0.88711289]\n",
      " [0.88611389 0.89410589 0.8951049  0.89110889 0.89010989 0.89010989\n",
      "  0.89110889 0.89110889 0.89110889]\n",
      " [0.89210789 0.89410589 0.89310689 0.89310689 0.89410589 0.89310689\n",
      "  0.89110889 0.89110889 0.89210789]\n",
      " [0.88811189 0.89010989 0.89110889 0.89210789 0.89010989 0.88911089\n",
      "  0.88911089 0.88811189 0.88811189]\n",
      " [0.88911089 0.89110889 0.89110889 0.89310689 0.89210789 0.89210789\n",
      "  0.89110889 0.89110889 0.89110889]\n",
      " [0.88511489 0.89110889 0.89210789 0.89310689 0.89210789 0.89210789\n",
      "  0.89110889 0.89110889 0.89210789]\n",
      " [0.88911089 0.8961039  0.89110889 0.89010989 0.89210789 0.89410589\n",
      "  0.89410589 0.89410589 0.89310689]\n",
      " [0.89210789 0.8981019  0.8971029  0.8971029  0.89410589 0.8951049\n",
      "  0.89410589 0.89310689 0.89210789]\n",
      " [0.89110889 0.8951049  0.8951049  0.8951049  0.89210789 0.89210789\n",
      "  0.89210789 0.89210789 0.89210789]\n",
      " [0.89010989 0.8981019  0.8971029  0.89410589 0.89410589 0.89310689\n",
      "  0.89310689 0.89410589 0.89410589]\n",
      " [0.88911089 0.8971029  0.8951049  0.89110889 0.89110889 0.89310689\n",
      "  0.89210789 0.89310689 0.89310689]\n",
      " [0.89010989 0.9000999  0.8971029  0.89410589 0.89410589 0.8951049\n",
      "  0.89310689 0.89410589 0.89310689]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 1. Setup arrays for k and p values\n",
    "k_values = list(range(1, 20))  # k from 1 to 9\n",
    "p_values = list(range(1, 10))   # p from 1 to 5\n",
    "\n",
    "# 2. Initialize accuracy matrices\n",
    "val_accuracies = np.zeros((len(k_values), len(p_values)))\n",
    "test_accuracies = np.zeros((len(k_values), len(p_values)))\n",
    "\n",
    "# 3. Compute accuracies\n",
    "for i, k in enumerate(k_values):\n",
    "    for j, p in enumerate(p_values):\n",
    "        acc_val = compute_accuracy(training_data, validation_data, k, p)\n",
    "        acc_test = compute_accuracy(training_data, test_data, k, p)\n",
    "        val_accuracies[i][j] = acc_val\n",
    "        test_accuracies[i][j] = acc_test\n",
    "        print(f\"k={k}, p={p}: val_acc={acc_val:.3f}, test_acc={acc_test:.3f}\")\n",
    "\n",
    "print(\"Validation Accuracies:\")\n",
    "print(val_accuracies)\n",
    "print(\"Test Accuracies:\")\n",
    "print(test_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Validation accuracy subplot\n",
    "plt.subplot(121)\n",
    "sns.heatmap(val_accuracies,\n",
    "            annot=True,\n",
    "            fmt='.3f',\n",
    "            xticklabels=p_values,\n",
    "            yticklabels=k_values,\n",
    "            cmap='viridis')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.xlabel('p value')\n",
    "plt.ylabel('k value')\n",
    "\n",
    "# Test accuracy subplot\n",
    "plt.subplot(122)\n",
    "sns.heatmap(test_accuracies,\n",
    "            annot=True,\n",
    "            fmt='.3f',\n",
    "            xticklabels=p_values,\n",
    "            yticklabels=k_values,\n",
    "            cmap='viridis')\n",
    "plt.title('Test Accuracy')\n",
    "plt.xlabel('p value')\n",
    "plt.ylabel('k value')\n",
    "\n",
    "# Save and display\n",
    "plt.tight_layout()\n",
    "plt.savefig('k_p_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ds_envi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
