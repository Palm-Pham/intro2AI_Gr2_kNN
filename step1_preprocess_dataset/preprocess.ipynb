{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import csv\n",
    "\n",
    "# Read the lines of the file updated_pollution_dataset.csv\n",
    "with open('updated_pollution_dataset.csv', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Separate the header from the rest of the lines\n",
    "header = lines[0]\n",
    "data_lines = lines[1:]\n",
    "\n",
    "# Shuffle the data lines\n",
    "random.shuffle(data_lines)\n",
    "\n",
    "# Write the shuffled lines to a new file called shuffled_pollution_dataset.csv\n",
    "with open('shuffled_pollution_dataset.csv', 'w', newline='') as f:\n",
    "    f.write(header)\n",
    "    f.writelines(data_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "       Temperature     Humidity        PM2.5         PM10          NO2  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
      "mean     30.029020    70.056120    20.142140    30.218360    26.412100   \n",
      "std       6.720661    15.863577    24.554546    27.349199     8.895356   \n",
      "min      13.400000    36.000000     0.000000    -0.200000     7.400000   \n",
      "25%      25.100000    58.300000     4.600000    12.300000    20.100000   \n",
      "50%      29.000000    69.800000    12.000000    21.700000    25.300000   \n",
      "75%      34.000000    80.300000    26.100000    38.100000    31.900000   \n",
      "max      58.600000   128.100000   295.000000   315.800000    64.900000   \n",
      "\n",
      "               SO2           CO  Proximity_to_Industrial_Areas  \\\n",
      "count  5000.000000  5000.000000                    5000.000000   \n",
      "mean     10.014820     1.500354                       8.425400   \n",
      "std       6.750303     0.546027                       3.610944   \n",
      "min      -6.200000     0.650000                       2.500000   \n",
      "25%       5.100000     1.030000                       5.400000   \n",
      "50%       8.000000     1.410000                       7.900000   \n",
      "75%      13.725000     1.840000                      11.100000   \n",
      "max      44.900000     3.720000                      25.800000   \n",
      "\n",
      "       Population_Density  \n",
      "count         5000.000000  \n",
      "mean           497.423800  \n",
      "std            152.754084  \n",
      "min            188.000000  \n",
      "25%            381.000000  \n",
      "50%            494.000000  \n",
      "75%            600.000000  \n",
      "max            957.000000  \n",
      "\n",
      "Found 1 negative values in PM10\n",
      "Negative values: [-0.2]\n",
      "\n",
      "Found 30 negative values in SO2\n",
      "Negative values: [-0.4 -0.1 -0.3 -1.9 -0.4 -6.2 -0.1 -0.3 -0.4 -0.3 -0.2 -4.1 -0.5 -1.2\n",
      " -2.8 -0.4 -0.1 -0.2 -0.3 -0.6 -1.7 -0.4 -1.4 -0.6 -0.5 -0.1 -3.4 -0.2\n",
      " -0.2 -0.2]\n",
      "\n",
      "After cleaning:\n",
      "       Temperature     Humidity        PM2.5         PM10          NO2  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
      "mean     30.029020    70.056120    20.142140    30.218400    26.412100   \n",
      "std       6.720661    15.863577    24.554546    27.349155     8.895356   \n",
      "min      13.400000    36.000000     0.000000     0.000000     7.400000   \n",
      "25%      25.100000    58.300000     4.600000    12.300000    20.100000   \n",
      "50%      29.000000    69.800000    12.000000    21.700000    25.300000   \n",
      "75%      34.000000    80.300000    26.100000    38.100000    31.900000   \n",
      "max      58.600000   128.100000   295.000000   315.800000    64.900000   \n",
      "\n",
      "               SO2           CO  Proximity_to_Industrial_Areas  \\\n",
      "count  5000.000000  5000.000000                    5000.000000   \n",
      "mean     10.020720     1.500354                       8.425400   \n",
      "std       6.740247     0.546027                       3.610944   \n",
      "min       0.000000     0.650000                       2.500000   \n",
      "25%       5.100000     1.030000                       5.400000   \n",
      "50%       8.000000     1.410000                       7.900000   \n",
      "75%      13.725000     1.840000                      11.100000   \n",
      "max      44.900000     3.720000                      25.800000   \n",
      "\n",
      "       Population_Density  \n",
      "count         5000.000000  \n",
      "mean           497.423800  \n",
      "std            152.754084  \n",
      "min            188.000000  \n",
      "25%            381.000000  \n",
      "50%            494.000000  \n",
      "75%            600.000000  \n",
      "max            957.000000  \n",
      "\n",
      "Cleaned data saved to cleaned_pollution_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def clean_negative_values(input_file, output_file):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(input_file)\n",
    "    \n",
    "    # All columns except the last one (label) should be non-negative\n",
    "    numeric_columns = df.columns[:-1]\n",
    "    \n",
    "    # Print statistics before cleaning\n",
    "    print(\"Before cleaning:\")\n",
    "    print(df[numeric_columns].describe())\n",
    "    \n",
    "    # Replace negative values with 0\n",
    "    for col in numeric_columns:\n",
    "        negative_count = (df[col] < 0).sum()\n",
    "        if negative_count > 0:\n",
    "            print(f\"\\nFound {negative_count} negative values in {col}\")\n",
    "            print(f\"Negative values: {df[df[col] < 0][col].values}\")\n",
    "            df[col] = df[col].clip(lower=0)\n",
    "    \n",
    "    # Print statistics after cleaning\n",
    "    print(\"\\nAfter cleaning:\")\n",
    "    print(df[numeric_columns].describe())\n",
    "    \n",
    "    # Save cleaned data\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"\\nCleaned data saved to {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = \"shuffled_pollution_dataset.csv\"\n",
    "    output_file = \"cleaned_pollution_dataset.csv\"\n",
    "    clean_negative_values(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def scale_values(input_file, output_file):\n",
    "    # Read CSV data\n",
    "    with open(input_file, 'r') as file:\n",
    "        file_csv = csv.reader(file)\n",
    "        header = next(file_csv)  # Skip header\n",
    "        \n",
    "        # Store data as features and labels\n",
    "        data = []\n",
    "        for row in file_csv:\n",
    "            features = [float(val) for val in row[:-1]]  # Convert features to float\n",
    "            label = row[-1]  # Keep label as string\n",
    "            data.append(features + [label])\n",
    "        \n",
    "        # Separate features and labels\n",
    "        features = np.array([row[:-1] for row in data])\n",
    "        labels = [row[-1] for row in data]\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        features_scaled = scaler.fit_transform(features)\n",
    "        \n",
    "        # Combine scaled features with labels\n",
    "        scaled_data = [list(row) + [label] for row, label in zip(features_scaled, labels)]\n",
    "        \n",
    "        # Write scaled data\n",
    "        with open(output_file, 'w', newline='') as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(header)\n",
    "            writer.writerows(scaled_data)\n",
    "\n",
    "input_file = \"cleaned_pollution_dataset.csv\"\n",
    "output_file = \"final_pollution_dataset.csv\"\n",
    "scale_values(input_file, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "# use this only when you know what you are doing\n",
    "\n",
    "import csv\n",
    "import random\n",
    "\n",
    "def add_noise(data, noise_level=0.01):\n",
    "    augmented_data = []\n",
    "    for row in data:\n",
    "        new_row = []\n",
    "        for val in row[:-1]:\n",
    "            noise = random.uniform(-noise_level, noise_level) * float(val)\n",
    "            new_val = float(val) + noise\n",
    "            new_row.append(new_val)\n",
    "        new_row.append(row[-1])\n",
    "        augmented_data.append(new_row)\n",
    "    return augmented_data\n",
    "\n",
    "# Read the original dataset\n",
    "with open('updated_pollution_dataset.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    data = [row for row in reader]\n",
    "\n",
    "# Augment the dataset\n",
    "augmented_data = add_noise(data)\n",
    "\n",
    "# Combine original and augmented data\n",
    "combined_data = data + augmented_data\n",
    "print(len(combined_data))\n",
    "# Write the combined data to a new file\n",
    "with open('augmented_pollution_dataset.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(combined_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_ds_envi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
